# ‚ö° QUICK START - 5 MINUTES

## üöÄ Ex√©cution en 5 √©tapes

### √âtape 1: Ouvrez 4 terminals PowerShell

Pour cela, appuyez 4 fois sur `Windows + Alt + T` ou ouvrez manuellement 4 PowerShell

---

## ‚úÖ Terminal 1: Infrastructure

Copier-coller ceci:

```powershell
cd C:\Users\khamm\OneDrive\Bureau\Kafka-SparkTreaming

# D√©marrer Docker
docker-compose up -d

# Attendre
Write-Host "Attente de 20 secondes..." -ForegroundColor Yellow
Start-Sleep -Seconds 20

# Cr√©er le topic
docker exec kafka kafka-topics --create --topic housing-data --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1 --if-not-exists

# Compiler le producer
cd producer
mvn clean package
cd ..

Write-Host "‚úÖ Infrastructure pr√™te!" -ForegroundColor Green
Write-Host "Allez au Terminal 2..." -ForegroundColor Cyan
```

‚è±Ô∏è **Temps: ~2-3 minutes** (attendre le Maven build)

---

## ‚úÖ Terminal 2: Spark Consumer

Copier-coller ceci:

```powershell
cd C:\Users\khamm\OneDrive\Bureau\Kafka-SparkTreaming

# Soumettre le job Spark
bash submit_consumer.sh

Write-Host "‚úÖ Spark Streaming Job soumis!" -ForegroundColor Green
```

‚è±Ô∏è **Temps: ~1 minute**

---

## ‚úÖ Terminal 3: Producer

Copier-coller ceci:

```powershell
cd C:\Users\khamm\OneDrive\Bureau\Kafka-SparkTreaming\producer

# Ex√©cuter le producer (envoie les donn√©es)
mvn exec:java@default

# Attendez de voir "Sent batch of X records" plusieurs fois
# puis que √ßa se termine
```

‚è±Ô∏è **Temps: ~30 secondes**

---

## ‚úÖ Terminal 4: V√©rification

Une fois que le Terminal 3 a fini, copier-coller ceci:

```powershell
cd C:\Users\khamm\OneDrive\Bureau\Kafka-SparkTreaming

# V√©rifier le nombre de records
docker exec postgres psql -U kafka_user -d kafka_streaming -c "SELECT COUNT(*) FROM housing;"

# R√©sultat attendu: 506 ‚úÖ
```

---

## üåê Ouvrir les Interfaces Web

Pendant que vous attendez, ouvrez ces URLs:

```powershell
Start-Process "http://localhost:8082"   # Kafka UI - voir les messages
Start-Process "http://localhost:8080"   # Spark - voir le job
Start-Process "http://localhost:5050"   # PgAdmin - voir les donn√©es
```

---

## üìã Checklist Finale

- [ ] Terminal 1: ‚úÖ Infrastructure pr√™te
- [ ] Terminal 2: ‚úÖ Spark job soumis
- [ ] Terminal 3: ‚úÖ Producer ex√©cut√© (6 batches envoy√©s)
- [ ] Terminal 4: ‚úÖ 506 records dans PostgreSQL
- [ ] Kafka UI: ‚úÖ Messages visibles
- [ ] Spark UI: ‚úÖ Application RUNNING
- [ ] PgAdmin: ‚úÖ Donn√©es pr√©sentes

---

## üéâ C'est Fait!

Le pipeline fonctionne! Les donn√©es CSV sont:
1. ‚úÖ Divis√©es en microbatches
2. ‚úÖ Envoy√©es via Kafka
3. ‚úÖ Trait√©es par Spark Streaming
4. ‚úÖ Stock√©es dans PostgreSQL

---

## üìñ Pour Aller Plus Loin

- **Documentation compl√®te**: Lire `README_COMPLET.md`
- **Commandes d√©taill√©es**: Lire `COMMANDES_PRINCIPALES.md`
- **Guide PowerShell**: Lire `POWERSHELL_GUIDE.md`
- **Troubleshooting**: Lire `GUIDE_EXECUTION.md`

---

## üÜò √áa N'a Pas March√©?

### Probl√®me: Terminal 1 - Maven timeout
**Solution**: Attendre plus longtemps ou relancer:
```powershell
cd producer
mvn clean package -T 1
```

### Probl√®me: Terminal 2 - psycopg2 error
**Solution**: D√©j√† install√© automatiquement, attendez juste
```powershell
docker exec spark-master pip install psycopg2-binary
```

### Probl√®me: Terminal 3 - Producer stuck
**Solution**: V√©rifier Kafka est ready:
```powershell
docker logs kafka | tail -20
```

### Probl√®me: Terminal 4 - 0 records
**Solution**: Attendez 60 secondes apr√®s que le Producer ait fini

### Probl√®me: Kafka UI/Spark UI ne marche pas
**Solution**: V√©rifier que les ports sont accessibles:
```powershell
docker ps  # V√©rifier que les services tournent
```

---

## ‚è∞ Chronom√©trage Attendu

| √âtape | Temps | Note |
|-------|-------|------|
| Terminal 1 | 2-3 min | Maven build inclus |
| Terminal 2 | 1 min | Soumission du job |
| Terminal 3 | 30 sec | Envoi des donn√©es |
| Terminal 4 | Imm√©diat | V√©rification |
| **TOTAL** | **~4-5 min** | ‚úÖ |

---

## üí° Tips

1. **Ne fermez pas les terminals** - ils continuent de tourner
2. **Les Web Interfaces** - ouvrez-les pendant le temps d'attente
3. **Les logs** - utiles pour d√©boguer si quelque chose ne marche pas
4. **PgAdmin** - login avec `admin@example.com / admin`

---

## üéØ Ensuite?

Explorez:
- Requ√™tes SQL avanc√©es dans PgAdmin
- Augmentez le batch size du Producer
- Monitorer en temps r√©el via Spark UI
- Exporter les donn√©es en CSV

