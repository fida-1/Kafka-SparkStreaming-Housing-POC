# üìã CHEAT SHEET - COMMANDES ESSENTIELLES

## üéØ EX√âCUTION COMPL√àTE EN 4 √âTAPES

### √âtape 1: Infrastructure (Terminal 1) - 2-3 min
```powershell
cd C:\Users\khamm\OneDrive\Bureau\Kafka-SparkTreaming
docker-compose up -d
Start-Sleep -Seconds 20
docker exec kafka kafka-topics --create --topic housing-data --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1 --if-not-exists
cd producer && mvn clean package && cd ..
```

### √âtape 2: Spark Consumer (Terminal 2) - 1 min
```powershell
cd C:\Users\khamm\OneDrive\Bureau\Kafka-SparkTreaming
bash submit_consumer.sh
```

### √âtape 3: Producer (Terminal 3) - 30 sec
```powershell
cd C:\Users\khamm\OneDrive\Bureau\Kafka-SparkTreaming\producer
mvn exec:java@default
```

### √âtape 4: V√©rification (Terminal 4) - 2 min
```powershell
cd C:\Users\khamm\OneDrive\Bureau\Kafka-SparkTreaming
Start-Sleep -Seconds 60
docker exec postgres psql -U kafka_user -d kafka_streaming -c "SELECT COUNT(*) FROM housing;"
```

‚úÖ **R√©sultat attendu:** `506`

---

## üåê WEB INTERFACES (Ouvrir dans le navigateur)

| Service | URL |
|---------|-----|
| Kafka UI | http://localhost:8082 |
| Spark Master | http://localhost:8080 |
| Spark Worker | http://localhost:8081 |
| PgAdmin | http://localhost:5050 |

**PgAdmin Credentials:**
- Email: `admin@example.com`
- Password: `admin`
- Server Host: `postgres`
- Server Port: `5432`
- Username: `kafka_user`
- Password: `kafka_pass`

---

## üîç V√âRIFICATIONS RAPIDES

### V√©rifier Docker
```powershell
docker ps
# R√©sultat: 7 containers
```

### V√©rifier Kafka Topic
```powershell
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092
# R√©sultat: housing-data
```

### V√©rifier Kafka Messages
```powershell
docker exec kafka kafka-console-consumer --topic housing-data --bootstrap-server localhost:9092 --from-beginning --max-messages 1
# R√©sultat: JSON array
```

### V√©rifier PostgreSQL
```powershell
docker exec postgres psql -U kafka_user -d kafka_streaming -c "SELECT COUNT(*) FROM housing;"
# R√©sultat: 506
```

### Voir Statistiques
```powershell
docker exec postgres psql -U kafka_user -d kafka_streaming -c "SELECT COUNT(*), AVG(medv), MIN(medv), MAX(medv) FROM housing;"
# R√©sultat: 506 | 22.53 | 5.0 | 50.0
```

---

## üìä REQU√äTES POSTGRESQL UTILES

### Nombre de records
```sql
SELECT COUNT(*) FROM housing;
```

### Tous les records
```sql
SELECT * FROM housing;
```

### Top 5 records
```sql
SELECT * FROM housing LIMIT 5;
```

### Records r√©cents
```sql
SELECT * FROM housing ORDER BY created_at DESC LIMIT 10;
```

### Statistiques
```sql
SELECT 
  COUNT(*),
  AVG(medv)::numeric(5,2),
  MIN(medv),
  MAX(medv)
FROM housing;
```

### Par colonne
```sql
SELECT 
  COUNT(*) as count,
  AVG(crim)::numeric(5,2) as avg_crime,
  AVG(rm)::numeric(5,2) as avg_rooms,
  AVG(medv)::numeric(5,2) as avg_price
FROM housing;
```

---

## üßπ NETTOYAGE

### Arr√™ter temporairement
```powershell
docker-compose stop
```

### Red√©marrer
```powershell
docker-compose start
```

### Arr√™ter compl√®tement
```powershell
docker-compose down
```

### Supprimer donn√©es ET containers
```powershell
docker-compose down -v
```

### Red√©marrer un service
```powershell
docker-compose restart spark-master
```

---

## üìú LOGS EN TEMPS R√âEL

### Logs Kafka
```powershell
docker logs -f kafka
```

### Logs Spark
```powershell
docker logs -f spark-master
```

### Logs PostgreSQL
```powershell
docker logs -f postgres
```

### Logs Spark Worker
```powershell
docker logs -f spark-worker
```

### Tous les logs
```powershell
docker-compose logs -f
```

### Derni√®res 20 lignes
```powershell
docker logs --tail 20 spark-master
```

---

## üÜò TROUBLESHOOTING RAPIDE

### Probl√®me: Timeout Maven
```powershell
cd producer
mvn clean package -X
```

### Probl√®me: Topic n'existe pas
```powershell
bash create_topic.sh
```

### Probl√®me: Spark n'a pas √©crit les donn√©es
```powershell
docker logs spark-master | tail -50
docker-compose restart spark-master
bash submit_consumer.sh
```

### Probl√®me: PostgreSQL vide
```powershell
# Attendre plus longtemps
Start-Sleep -Seconds 120
docker exec postgres psql -U kafka_user -d kafka_streaming -c "SELECT COUNT(*) FROM housing;"
```

### Probl√®me: Docker ne d√©marre pas
```powershell
docker-compose up -d --force-recreate
```

### Probl√®me: psycopg2 not found
```powershell
docker exec spark-master pip install psycopg2-binary
bash submit_consumer.sh
```

---

## üíæ SAUVEGARDE ET RESTORE

### Exporter les donn√©es
```powershell
docker exec postgres pg_dump -U kafka_user kafka_streaming > backup.sql
```

### Importer les donn√©es
```powershell
docker exec -i postgres psql -U kafka_user kafka_streaming < backup.sql
```

### Vider la table
```powershell
docker exec postgres psql -U kafka_user -d kafka_streaming -c "TRUNCATE housing;"
```

---

## üìä RESSOURCES UTILIS√âES

### Voir la m√©moire et CPU
```powershell
docker stats
```

### Voir sans refresh
```powershell
docker stats --no-stream
```

### Voir juste Spark
```powershell
docker stats spark-master spark-worker
```

---

## üîë CREDENTIALS

| Service | Key | Value |
|---------|-----|-------|
| **PostgreSQL** | User | kafka_user |
| **PostgreSQL** | Password | kafka_pass |
| **PostgreSQL** | Database | kafka_streaming |
| **PostgreSQL** | Port | 5432 |
| **PgAdmin** | Email | admin@example.com |
| **PgAdmin** | Password | admin |
| **Kafka** | External | localhost:9092 |
| **Kafka** | Internal | kafka:29092 |
| **Spark Master** | Host | spark-master |
| **Spark Master** | Port | 7077 |

---

## üìÅ CHEMINS IMPORTANTS

```
Racine:        C:\Users\khamm\OneDrive\Bureau\Kafka-SparkTreaming
Producer:      C:\Users\khamm\OneDrive\Bureau\Kafka-SparkTreaming\producer
Code Java:     producer\src\main\java\com\example\KafkaProducerApp.java
CSV:           producer\housing.csv
Python:        consumer\consumer.py
Config:        docker-compose.yml, init.sql
```

---

## ‚è±Ô∏è TIMELINE

| √âtape | Commande | Dur√©e |
|-------|----------|-------|
| T1 | Infrastructure | 2-3 min |
| T2 | Spark job | 1 min |
| T3 | Producer | 30 sec |
| T4 | V√©rification | 1-2 min |
| **TOTAL** | | **~5-7 min** |

---

## ‚úÖ CHECKLIST SUCCESS

- [ ] Terminal 1: ‚úÖ Infrastructure pr√™te
- [ ] Terminal 2: ‚úÖ Spark job soumis
- [ ] Terminal 3: ‚úÖ 6 batches envoy√©s
- [ ] Terminal 4: ‚úÖ 506 records en BD
- [ ] Kafka UI: ‚úÖ Messages visibles
- [ ] Spark UI: ‚úÖ Application RUNNING
- [ ] PgAdmin: ‚úÖ Donn√©es pr√©sentes

---

## üéØ R√âSUM√â EN 1 PAGE

```
1. Ouvrir 4 terminaux PowerShell

2. Terminal 1:
   cd C:\Users\khamm\OneDrive\Bureau\Kafka-SparkTreaming
   docker-compose up -d
   Start-Sleep -Seconds 20
   docker exec kafka kafka-topics --create --topic housing-data --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1 --if-not-exists
   cd producer && mvn clean package && cd ..

3. Terminal 2:
   cd C:\Users\khamm\OneDrive\Bureau\Kafka-SparkTreaming
   bash submit_consumer.sh

4. Terminal 3:
   cd C:\Users\khamm\OneDrive\Bureau\Kafka-SparkTreaming\producer
   mvn exec:java@default

5. Terminal 4 (apr√®s 60 sec):
   cd C:\Users\khamm\OneDrive\Bureau\Kafka-SparkTreaming
   docker exec postgres psql -U kafka_user -d kafka_streaming -c "SELECT COUNT(*) FROM housing;"

6. Ouvrir navigateur:
   http://localhost:8082  (Kafka UI)
   http://localhost:8080  (Spark)
   http://localhost:5050  (PgAdmin)

7. R√©sultat: 506 records ‚úÖ
```

---

## üìö DOCUMENTATION COMPL√àTE

Pour plus de d√©tails, voir:
- `START_HERE.md` - Point de d√©part
- `QUICK_START_5MIN.md` - D√©marrage rapide
- `TOUTES_LES_COMMANDES.md` - Toutes les commandes
- `README_COMPLET.md` - Guide complet
- `GUIDE_EXECUTION.md` - Instructions d√©taill√©es

---

**Imprimez cette feuille et gardez-la √† proximit√©!** üñ®Ô∏è

