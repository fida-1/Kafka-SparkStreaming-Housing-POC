# Guide Complet - Pipeline Kafka Spark Streaming ‚Üí PostgreSQL

## üìä Architecture du Pipeline

```
CSV (housing.csv)
    ‚Üì
Java Producer (microbatches de 100 records)
    ‚Üì
Kafka Topic (housing-data)
    ‚Üì
Spark Streaming Consumer
    ‚Üì
PostgreSQL Database
```

---

## üöÄ √âTAPE 1 : D√©marrer l'Infrastructure Docker

```powershell
# √Ä la racine du projet
docker-compose up -d

# V√©rifier que tous les services sont en cours d'ex√©cution
docker ps
```

**Attendez 20-30 secondes** pour que tous les services soient compl√®tement pr√™ts.

---

## ‚úÖ √âTAPE 2 : Cr√©er le Topic Kafka

```bash
# Ex√©cuter le script de cr√©ation du topic
bash create_topic.sh
```

Ou manuellement :
```powershell
docker exec kafka kafka-topics --create `
  --topic housing-data `
  --bootstrap-server localhost:9092 `
  --partitions 1 `
  --replication-factor 1 `
  --if-not-exists
```

**V√©rifier que le topic a √©t√© cr√©√© :**
```powershell
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092
```

---

## üî® √âTAPE 3 : Compiler et Ex√©cuter le Producer Java

### 3a) Naviguer et compiler
```powershell
cd producer
mvn clean package
```

### 3b) Ex√©cuter le Producer
```powershell
mvn exec:java@default -Dexec.mainClass="com.example.KafkaProducerApp"
```

Vous verrez des messages comme :
```
Sent batch of 100 records to Kafka
Sent batch of 100 records to Kafka
...
```

---

## üîÑ √âTAPE 4 : Soumettre le Job Spark Streaming

### √Ä partir de la racine du projet:
```bash
bash submit_consumer.sh
```

Cela va :
1. ‚úÖ Attendre que Spark soit pr√™t
2. ‚úÖ Copier le script consumer.py
3. ‚úÖ Installer les d√©pendances Python
4. ‚úÖ Soumettre le job au cluster Spark

**Attendez que vous voyiez :**
```
Sent batch of 100 records to Kafka
```

---

## üì° √âTAPE 5 : V√©rifier les Web Interfaces

### üîµ Kafka UI (visualiser les topics et messages)
```
http://localhost:8082
```

**Actions :**
- Voir le topic `housing-data`
- V√©rifier les messages en temps r√©el
- Voir les partitions

### üü† Spark Master UI (visualiser les jobs)
```
http://localhost:8080
```

**Actions :**
- Voir le cluster Spark
- Voir les workers connect√©s
- Monitorer les applications en cours

### üü† Spark Worker UI
```
http://localhost:8081
```

**Actions :**
- Voir les ressources utilis√©es
- Voir les executors

### üêò PgAdmin (g√©rer PostgreSQL)
```
http://localhost:5050
```

**Connexion :**
- Email: `admin@example.com`
- Password: `admin`

**Ajouter le serveur PostgreSQL :**
- Host: `postgres`
- Port: `5432`
- Username: `kafka_user`
- Password: `kafka_pass`
- Database: `kafka_streaming`

---

## üîç √âTAPE 6 : V√©rifier les Donn√©es dans PostgreSQL

### Via Terminal (psql)
```powershell
# Nombre total de records
docker exec -it postgres psql -U kafka_user -d kafka_streaming -c "SELECT COUNT(*) FROM housing;"

# Voir les 10 premiers records
docker exec -it postgres psql -U kafka_user -d kafka_streaming -c "SELECT * FROM housing LIMIT 10;"

# Voir les statistiques
docker exec -it postgres psql -U kafka_user -d kafka_streaming -c "SELECT COUNT(*), AVG(medv), MIN(medv), MAX(medv) FROM housing;"

# Voir les donn√©es r√©centes
docker exec -it postgres psql -U kafka_user -d kafka_streaming -c "SELECT * FROM housing ORDER BY created_at DESC LIMIT 5;"
```

### Via PgAdmin (Interface Web)
1. Allez √† http://localhost:5050
2. Connectez-vous avec `admin@example.com / admin`
3. Cliquez sur le serveur PostgreSQL
4. Naviguez vers `databases ‚Üí kafka_streaming ‚Üí schemas ‚Üí public ‚Üí tables ‚Üí housing`
5. Cliquez sur "View All Rows"

---

## üß™ √âTAPE 7 : V√©rifier les Messages Kafka

### Consommer les messages du topic
```powershell
docker exec kafka kafka-console-consumer `
  --topic housing-data `
  --bootstrap-server localhost:9092 `
  --from-beginning `
  --max-messages 2
```

### Voir les statistiques du topic
```powershell
docker exec kafka kafka-topics --describe `
  --topic housing-data `
  --bootstrap-server localhost:9092
```

---

## üõë √âTAPE 8 : Arr√™ter le Pipeline

### Arr√™ter et supprimer tous les containers
```powershell
docker-compose down
```

### Supprimer aussi les volumes (donn√©es persistantes)
```powershell
docker-compose down -v
```

---

## üìã Commandes Utiles pour le Debugging

### Voir les logs du Producer
```powershell
cd producer
mvn exec:java@default -Dexec.mainClass="com.example.KafkaProducerApp" 2>&1 | Tee-Object -FilePath producer.log
```

### Voir les logs du Spark Job
```powershell
docker logs -f spark-master
```

### Voir les logs du Consumer Kafka
```powershell
docker logs -f kafka
```

### Voir les logs de PostgreSQL
```powershell
docker logs -f postgres
```

### Acc√©der au conteneur Spark pour d√©boguer
```powershell
docker exec -it spark-master bash
# √Ä l'int√©rieur du conteneur:
ls -la /opt/spark/work-dir/
cat consumer.py
```

### V√©rifier la connexion PostgreSQL depuis Spark
```powershell
docker exec spark-master python -c "import psycopg2; print('psycopg2 OK')"
```

---

## ‚ö†Ô∏è Probl√®mes Courants et Solutions

### ‚ùå "Topic does not exist"
```powershell
bash create_topic.sh
```

### ‚ùå "Connection refused to postgres"
- V√©rifier que le conteneur postgres est en cours d'ex√©cution: `docker ps | grep postgres`
- Attendre 10 secondes apr√®s `docker-compose up -d`

### ‚ùå "Spark job not receiving messages"
- V√©rifier que le Producer a envoy√© les donn√©es: `docker exec kafka kafka-console-consumer --topic housing-data --bootstrap-server localhost:9092 --from-beginning --max-messages 1`
- V√©rifier les logs Spark: `docker logs spark-master`

### ‚ùå "No data in PostgreSQL"
- V√©rifier que le Spark job s'ex√©cute correctement
- V√©rifier les logs: `docker logs spark-master | tail -50`
- V√©rifier la table existe: `docker exec -it postgres psql -U kafka_user -d kafka_streaming -c "\dt"`

### ‚ùå "psycopg2 not found"
- Le script `submit_consumer.sh` installe automatiquement psycopg2
- Si probl√®me persiste: `docker exec spark-master pip install --upgrade psycopg2-binary`

---

## üìä Flux d'Ex√©cution Complet (Quick Start)

```powershell
# 1. D√©marrer Docker
docker-compose up -d
Start-Sleep -Seconds 20

# 2. Cr√©er le topic
bash create_topic.sh

# 3. Compiler le Producer
cd producer
mvn clean package
cd ..

# 4. Soumettre le Consumer Spark
bash submit_consumer.sh

# 5. Ex√©cuter le Producer (dans un autre terminal PowerShell)
cd producer
mvn exec:java@default

# 6. V√©rifier dans un 3√®me terminal
docker exec -it postgres psql -U kafka_user -d kafka_streaming -c "SELECT COUNT(*) FROM housing;"

# 7. Ouvrir les interfaces web
# - Kafka UI: http://localhost:8082
# - Spark: http://localhost:8080
# - PgAdmin: http://localhost:5050
```

---

## üéØ Points de V√©rification

- ‚úÖ `docker ps` : 7 services actifs (zookeeper, kafka, postgres, spark-master, spark-worker, kafka-ui, pgadmin)
- ‚úÖ Kafka UI : topic `housing-data` visible avec messages
- ‚úÖ Spark UI : application en cours d'ex√©cution
- ‚úÖ PostgreSQL : table `housing` remplie avec les donn√©es
- ‚úÖ PgAdmin : connexion au DB OK, donn√©es visibles

